1. Introduction
	•	Context: Image classification and domain-specific features
	•	Motivation: Why source identification in CINIC-10 is interesting
	•	Research Question: Can models distinguish between CIFAR-10 and ImageNet sources?
	•	Overview of methods and results
	•	Structure of the report

⸻

2. Background and Related Work
	•	Brief overview of CIFAR-10, ImageNet, and CINIC-10
	•	Domain adaptation / dataset bias
	•	Label noise and dataset quality (mention Northcutt et al., 2021)
	•	Previous work on visual domain shift and shallow biases

⸻

3. Dataset and Preprocessing
	•	Description of CINIC-10: structure, class labels, image sizes
	•	Your preprocessing steps:
	•	How you labeled source domain (filename heuristics)
	•	Data splits (train/valid/test)
	•	RGB statistics (mean/variance per class and source)
	•	Discussion of visual differences between domains (e.g. “stock image”-like properties)

⸻

4. Methodology
	•	Goal: Binary classification (source: CIFAR-10 vs. ImageNet)
	•	Data preparation (custom data loaders/generators)
	•	Models:
	•	Baseline: Random guessing, shallow MLP
	•	Convolutional Neural Network (CNN)
	•	Vision Transformer (ViT) or non-convolutional models
	•	Random Forest (on flattened data or RGB stats)
	•	Training setup (loss, optimizer, epochs, batch size, etc.)

⸻

5. Experiments and Results
	•	Evaluation metrics (accuracy, precision, recall, etc.)
	•	Comparison of models
	•	Confusion matrices
	•	Visualizations:
	•	Feature maps, filters (kernels), and learned representations
	•	Example predictions (correct/wrong by class and source)
	•	Effect of image properties (e.g. RGB variance)

⸻

6. Discussion
	•	What the models learned to identify (centeredness, contrast, etc.)
	•	Interpretation of feature maps and filters
	•	Limitations (e.g., label noise, overfitting to domain artifacts)
	•	Does the model rely on semantic content or image statistics?

⸻

7. Conclusion and Outlook
	•	Summary of findings
	•	Answer to the research question
	•	What could be improved (e.g., larger models, different feature types)
	•	Possible extensions (e.g., domain generalization, synthetic data)

⸻

8. References
	•	Use BibTeX or \begin{thebibliography} to cite papers like:
	•	Northcutt et al., 2021
	•	CINIC-10 paper
	•	scikit-learn, TensorFlow/Keras documentation

⸻

9. Appendix (Optional)
	•	Full RGB/variance tables
	•	Additional plots
	•	Training logs
	•	Code snippets